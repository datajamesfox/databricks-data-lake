{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a1d98a-ac44-4ae2-97f4-7bf6864b9ce9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, split, add_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e83c83-b55a-443c-82ec-9e08aa57752c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "AWS_ACCESS_KEY_ID= \"123\"\n",
    "AWS_SECRET_ACCESS_KEY= \"123\"\n",
    "aws_bucket_name = \"s3a://abc/\"\n",
    "aws_container_name = \"/bronze/csv/\"\n",
    "aws_file_name = \"insurance_data.csv\"\n",
    "\n",
    "# Set AWS Access\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_ACCESS_KEY_ID)\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b44981-b724-4c3c-9ee7-cf5d56cdd58a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read Bronze csv\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"{aws_bucket_name}{aws_container_name}{aws_file_name}\")\n",
    "\n",
    "# Delta table output path\n",
    "aws_container_name = '/bronze/delta/'\n",
    "\n",
    "# Write Delta table\n",
    "df.write.format('delta').mode('overwrite').save(f\"{aws_bucket_name}{aws_container_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26b7a91c-bfe6-4067-a98e-c29e74ae5909",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load delta file\n",
    "df = spark.read.load(f\"{aws_bucket_name}{aws_container_name}\")\n",
    "\n",
    "# Check schema\n",
    "df.printSchema()\n",
    "\n",
    "# Display data\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "867c4d85-1ac4-48ae-82e7-997589a45eab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split ​product_identifier\n",
    "df2 = df.withColumn('country', split(col('product_identifier'), '_')[0]) \\\n",
    "           .withColumn('vertical', split(col('product_identifier'), '_')[1]) \\\n",
    "           .withColumn('vehicle', split(col('product_identifier'), '_')[3])\n",
    "\n",
    "# Cast correct data types - leave string as default\n",
    "df3 = df2.withColumn('user_id', col('user_id').cast('int')) \\\n",
    "       .withColumn('inception_policy_id', col('inception_policy_id').cast('int')) \\\n",
    "       .withColumn('adjustment_policy_id', col('adjustment_policy_id').cast('int')) \\\n",
    "       .withColumn('change_number', col('change_number').cast('int')) \\\n",
    "       .withColumn('effective_start_date', to_date(col('effective_start_date'), 'dd/MM/yyyy')) \\\n",
    "       .withColumn('effective_end_date', to_date(col('effective_end_date'), 'dd/MM/yyyy')) \\\n",
    "       .withColumn('ftp_start_date', to_date(col('ftp_start_date'), 'dd/MM/yyyy').cast('date')) \\\n",
    "       .withColumn('ftp_valid_until', to_date(col('ftp_valid_until'), 'dd/MM/yyyy').cast('date')) \\\n",
    "       .withColumn('flex_policy_earned_hours', col('flex_policy_earned_hours').cast('int')) \\\n",
    "       .withColumn('transaction_gwp', col('transaction_gwp').cast('float')) \\\n",
    "       .withColumn('policy_total_gwp', col('policy_total_gwp').cast('float'))\n",
    "\n",
    "# Rename columns\n",
    "df4 = df3.withColumnRenamed(\"user_id\", \"UserID\") \\\n",
    "       .withColumnRenamed(\"product_identifier\", \"ProductID\") \\\n",
    "        .withColumnRenamed(\"frequency_type\", \"FrequencyType\") \\\n",
    "       .withColumnRenamed(\"inception_policy_id\", \"InceptionPolicyID\") \\\n",
    "       .withColumnRenamed(\"adjustment_policy_id\", \"AdjustmentPolicyID\") \\\n",
    "       .withColumnRenamed(\"change_number\", \"PolicyChangeNumber\") \\\n",
    "       .withColumnRenamed(\"transaction_type\", \"TransactionType\") \\\n",
    "       .withColumnRenamed(\"effective_start_date\", \"EffectiveStartDate\") \\\n",
    "       .withColumnRenamed(\"effective_end_date\", \"EffectiveEndDate\") \\\n",
    "       .withColumnRenamed(\"ftp_start_date\", \"FTPStartDate\") \\\n",
    "       .withColumnRenamed(\"ftp_valid_until\", \"FTPValidUnitl\") \\\n",
    "       .withColumnRenamed(\"flex_policy_earned_hours\", \"FlexPolicyHoursEarned\") \\\n",
    "       .withColumnRenamed(\"transaction_gwp\", \"GrossWrittenPremium\") \\\n",
    "       .withColumnRenamed(\"policy_total_gwp\", \"TotalGrossWrittenPremium\") \\\n",
    "       .withColumnRenamed(\"country\", \"Country\") \\\n",
    "       .withColumnRenamed(\"vertical\", \"Vertical\") \\\n",
    "       .withColumnRenamed(\"vehicle\", \"Vehicle\")\n",
    "\n",
    "# Check schema\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb20c69b-b885-4b96-a9d6-e234f646c2df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delta table output path\n",
    "aws_container_name = 'silver/delta/'\n",
    "\n",
    "# Write Silver Delta table\n",
    "df4.write.format('delta').mode('overwrite').save(f\"{aws_bucket_name}{aws_container_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac63141-476d-4a36-a456-978fc6a625aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Set variables\n",
    "SET delta_source.var = 's3://abc/silver/delta/';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b67fd578-48df-43e1-ad37-3bca20910148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create Table\n",
    "CREATE TABLE IF NOT EXISTS delivery_transactions USING DELTA LOCATION ${delta_source.var};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db65cc7f-2ff3-416b-8616-5f9840594028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Number of customers that purchased at least 1 ​Fixed​ policy\n",
    "SELECT\n",
    "  COUNT(DISTINCT UserID) AS FixedPolicyCustomerCount\n",
    "FROM\n",
    "  delivery_transactions\n",
    "WHERE\n",
    "  FrequencyType IN ('short', 'annual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6f492eb-5640-42a9-9dcc-9d19924d7089",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Average hourly premium by ​product_identifier​ for all the ​Flex products\n",
    "SELECT\n",
    "  ProductID,\n",
    "  AVG(GrossWrittenPremium / FlexPolicyHoursEarned) AS AvgHourlyPremium\n",
    "FROM\n",
    "  delivery_transactions\n",
    "WHERE\n",
    "  FrequencyType = 'flex'\n",
    "GROUP BY\n",
    "  ProductID;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8716fab9-c98d-4614-af5e-975e053c24aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Rolling monthly GWP generated by each ​product_identifier\n",
    "SELECT\n",
    "  ProductID,\n",
    "  EffectiveStartDate,\n",
    "  SUM(GrossWrittenPremium) OVER (\n",
    "    PARTITION BY ProductID\n",
    "    ORDER BY\n",
    "      EffectiveStartDate RANGE BETWEEN INTERVAL 1 MONTH PRECEDING\n",
    "      AND CURRENT ROW\n",
    "  ) AS RollingMonthlyGWP\n",
    "FROM\n",
    "  delivery_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d20a85-7e71-45c1-9c53-a93451fd6e78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Policies of all the customers that purchased a ​Fixed​ product and ​Cancelled​ grouped by year and month\n",
    "SELECT\n",
    "  UserID ProductID,\n",
    "  InceptionPolicyID,\n",
    "  YEAR(EffectiveStartDate) AS Year,\n",
    "  MONTH(EffectiveStartDate) AS Month,\n",
    "  PolicyChangeNumber,\n",
    "  TransactionType,\n",
    "  GrossWrittenPremium\n",
    "FROM\n",
    "  delivery_transactions\n",
    "WHERE\n",
    "  InceptionPolicyID IN (\n",
    "    SELECT\n",
    "      InceptionPolicyID\n",
    "    FROM\n",
    "      delivery_transactions\n",
    "    WHERE\n",
    "      TransactionType = 'Cancellation'\n",
    "  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "222888b6-2bdf-4c2a-8bd2-71ee4f24a09d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark SQL has no recursive CTEs so utilise Pyspark\n",
    "\n",
    "df = spark.read.load(f\"{aws_bucket_name}{aws_container_name}\")\n",
    "\n",
    "df = df.withColumn(\"EffectiveStartDate\", col(\"EffectiveStartDate\").cast(\"date\"))\n",
    "\n",
    "min_max_dates = df.selectExpr(\"min(EffectiveStartDate) as min_date\", \"max(EffectiveStartDate) as max_date\") \\\n",
    "                  .collect()[0]\n",
    "\n",
    "min_date = min_max_dates[\"min_date\"]\n",
    "max_date = min_max_dates[\"max_date\"]\n",
    "date = max_date\n",
    "date_list = []\n",
    "\n",
    "while date > min_date:\n",
    "    df.select(add_months(df.EffectiveStartDate, 1).alias('next_month')).collect()\n",
    "\n",
    "# Cross Join UserIDs\n",
    "# Window Function First occurance of UserID\n",
    "# \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Insurance Process",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
